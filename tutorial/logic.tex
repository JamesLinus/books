% vim: ft=tex ff=unix ts=4 sw=4 et wm=8 tw=0

\chapter{Logic and Logic Programming}

\XXX{Convert all logic to tt and Mercury syntax.  Add comments in the
intro to make it clear what it would look like in a logic text book.}

While programming in a purely functional style is a fairly intuitive
notion, the notion of programming in logic might at first seem a little
odd.  Nevertheless, in this section we shall demonstrate that there is
an easily understood logic-based programming paradigm.  A firm grasp of
logic is a great help in understanding Mercury, so we start with a
refresher course on basic logic.

\section{The Abstract Stuff}

To quote Douglas Adams, \emph{Don't Panic!}

\subsection{What's the Point?}

Logics help us to reason about the world.  Ordinary, natural language is
generally too verbose and too imprecise to use effectively in complex
situations.  When thinking about computer programs the problem is
exacerbated because computers take everything we say to them literally
and they have absolutely no imagination.

A logic allows us to say simple things clearly and concisely and gives
us an unambiguous mechanism for deducing more complex things thereafter.

The simplicity of logic can be deceptive in two ways.  The first is it
often seems \emph{too} simple to be of any use.  The second is that one
is often tempted to say of a particular statement, ``Why do we need
logic here?  This is clearly correct.''  The answer in both cases is
that you'd be amazed at how often these points of view are wrong.

Finally, when we use logic to help us think about and solve problems on
paper, we can very often turn that effort directly into a reliable,
working computer program with the minimum of effort.

\subsection{What Is a Logic?}

In the most abstract sense, a \emph{logic} consists of
\being{itemize}
\item a \emph{language} which specifies the set of well formed
\emph{sentences}, and
\item a set of \emph{inference rules} which allow us to deduce new
sentences from a given set of sentences.
\end{itemize}
A sentence is often also referred to as a \emph{formula}.  We will use
both terms interchangably throughout the book.

\subsection{What is a Theory?}

A theory is the set of sentences that can be obtained with respect to a
particular logic where each sentence is either
\begin{itemize}
\item a member of a particular starting set of \emph{axioms}, which are
taken to be ``true without proof'', or
\item can be \emph{proved} from other sentences in the theory.
\end{itemize}
A sentence in a theory is referred to as a \emph{theorem}.

\subsection{What is a Proof?}

A \emph{proof} is a sequence of sentences where each step is either
\begin{itemize}
\item an axiom or
\item a sentence obtained by application of an inference rule to one or
more of the preceding sentences in the proof.
\end{itemize}

\subsection{What is an Interpretation?}

An \emph{interpretation} can be viewed as the set of sentences that are
true in a particular problem domain, all other sentences being deemed to
be false.  One way of looking at an interpretaion is as a way of
relating sentences in the logic to things in the problem domain.

\subsection{Consistency, Completeness and Correctness}

A theory is \emph{consistent} if it does not contain any mutually
contradictory theorems.

A theory is \emph{complete} with respect to an interpretation if the
interpretation is a subset of the theory (otherwise the interpretation
contains some sentences that are true but are not part of the theory.)

A theory is \emph{correct} with respect to an interpretation if it is a
subset of the interpretation (otherwise the theory claims some theorems
are true that are in fact false under the given interpretation.)

\subsection{Putting it All Together}

So, for any particular problem, we need the following if we are going to
reason about it logically:
\begin{itemize}
\item a language defining the sentences we can consider;
\item a set of rules allowing us to deduce new sentences from old;
\item a set of axioms defining our starting point;
\item an interpretation connecting the results of our abstract, logical
efforts to the problem domain we are interested in.
\end{itemize}

\section{Propositional Logic}

The simplest useful logic is the \emph{propositional calculus}.
The propositional calculus is used to reason about logical formulae
composed of atomic propositions -- that is, simple statements that are
either true or false.

In what follows we use @P@ and @Q@ to stand for arbitrary sentences.

\subsection{Language}

\begin{itemize}
\item We use @word@s or letters, @a@, @b@, @c@, \ldots to stand for
\emph{atomic} propositions;
\item we usually include @true@ as a proposition that is true in all
interpretations and @false@ as a proposition that is false in all
interpretations;
\item @not P@ stands for the \emph{negation} ``@P@ is false'';
\item @(P, Q)@ stands for the \emph{conjunction} ``@P@ and @Q@'' meaning
\emph{both} @P@ and @Q@ are true;
\item @(P ; Q)@ stands for the \emph{disjunction} ``@P@ or @Q@'' meaning
\emph{at least one of} @P@ and @Q@ is true;
\item @(P => Q)@ stands for the \emph{implication} ``if @P@ then @Q@''
meaning if @P@ is true, then @Q@ must be true (it says nothing about @Q@
in the case where @P@ is false).  @P@ is referred to as the
\emph{antecedent} and @Q@ as the \emph{consequent} of the implication.
\end{itemize}

We may occasionally use @(Q <= P)@ as a convenient notation for
@(P => Q)@ and @(P <=> Q)@ for @((P => Q), (P <= Q))@ (the latter type
of formula is called an \emph{equivalence}).

\textbf{Note on syntax:} we use Mercury style syntax throughout this
chapter.  Books on logic will tend to use slightly different symbols for
the logical connectives:
\begin{itemize}
\item @not P@ is conventionally written as $\Not$@P@;
\item @(P, Q)@ is conventionally written as @P@$\Conj$@Q@;
\item @(P ; Q)@ is conventionally written as @P@$\Disj$@Q@;
\item @(P => Q)@ is conventionally written as @P@$\Imp$@Q@.

\subsection{Rules of Inference}

We present rules of inference using \emph{sequent notation}.  Sequents
can be read thus: given sentences matching what appears above the line,
we may deduce the sentence below the line.

We can always infer @true@, which is the negation of @false@.
The double negation of a proposition is the same as asserting that
proposition.
\begin{verbatim}
                                not not P       P
-----           ----------      ----------      ----------
true            not false       P               not not P
\end{verbatim}
(If we omit the double negation rule then we have an intuitionistic
logic.)

We can form the conjunction of any two true propositions.
We can reorder conjunctions.
We can project a conjunct from a conjunction.
Conjunction with any false proposition is also false.
\begin{verbatim}
P
Q               P, Q            P, Q            not P
-----           -----           -----           ----------
P, Q            Q, P            P               not (P, Q)
\end{verbatim}
Conjunction is therefore commutative and associative.

We can form a disjunction of any other proposition with a true
proposition.
We can reorder disjunctions.
If a disjunction is false then so are its disjuncts.
\begin{verbatim}
                                                not P
P               P ; Q           not (P ; Q)     not Q
------          ------          ------------    ------------
P ; Q           Q ; P           not P           not (P ; Q)
\end{verbatim}
Disjunction is therefore commutative and associative.

If the antecedent of an implication is true then the consequent must
also be true (\emph{modus ponens}).
If the consequent of an implication is false then the antecedent must
also be false (\emph{modus tollens}).
We can introduce an implication using any proposition at all for a true
consequent or a false antecedent:
\begin{verbatim}
P               not Q
P => Q          P => Q          Q               not P
-------         -------         -------         -------
Q               not P           P => Q          P => Q
\end{verbatim}

\subsection{On Implication}

The rules for implication might seem a little odd.  One should be
careful to avoid confusing logical implication with causation.  With
causation, the consequent must follow ``because'' of the antecedent.
Logical implication, on the other hand, need not make any kind sense.
It is perfectly all right to put any proposition at all on either side
of a logical implication; whether the implication is justified or not is
another matter entirely and is dictated by its context within a theory
or proof.

Another common source of confusion is that implication says nothing
about what happens if the antecedent is false.  The idea is that if we
have @(P => Q)@ and also @not P@ then the implication isn't
``triggered'' and hence cannot make any false claim.  The only situation
where an implication @(P => Q)@ is false is if @P@ is true, but @Q@ is
\emph{false}.  In this case the implication is ``triggered'', but
contradicts @not Q@ which has already been established.  Consequently,
if we have @(P => Q)@ and we know that @Q@ is false then the only
consistent deduction is that @P@ is also false.

\subsection{Some Basic Proofs}

It is instructive to see some simple proofs.  When constructing a proof
we work bottom-up: we start with the theorem we wish to prove and then
use the inference rules in reverse to get back to whatever we've allowed
ourselves to take as given.

First off, let's show that from @(false ; P)@ we can infer @P@:
\begin{verbatim}
 1      (false ; P)             given

 2      not false               from the negation rules
 3      P                       resolution of 2 and 1
\end{verbatim}

Next, let's show that @not (false, P)@ is always true:
\begin{verbatim}
 1      not false               from the negation rules
 2      not (false, P)          from the conjunction rules and 1
\end{verbatim}

The following relationship is extremely useful: @(P => Q)@ is equivalent
to @(not P ; Q)@.  We prove this in two stages, first starting with the
assumption @(not P ; Q)@.
Since we start with a disjunction, it is sufficient to show that if each
disjunct independently supports the conclusion then the disjunction as a
whole must support the conclusion.
\begin{verbatim}
 1      (not P ; Q)             given

 2.L    not P                   assuming the left hand side of 1
 3.L    (P => Q)                from the implication rules and 2.L

 2.R    Q                       assuming the right hand side of 1
 3.R    (P => Q)                from the implication rules and 2.R

 4      (P => Q)                from 1, 3.L and 3.R
\end{verbatim}
To finish, we start with the assumption @(P => Q)@.  Since we start with
an implication, it is sufficient to show that we can prove @(not P ; Q)@
if either the antecedent is false or the consequent is true.
\begin{verbatim}
 1      (P => Q)                given

 2.L    not P                   assuming the antecedent of 1 is false
 3.L    (not P ; Q)             from the disjunction rules and 2.L

 2.R    Q                       assuming the consequent of 1
 3.R    (not P ; Q)             from the disjunction rules and 2.R

 4      (not P ; Q)             from 1, 3.L and 3.R
\end{verbatim}

Augustus De Morgan, the 19th century logician, showed that @not (P, Q)@
is equivalent to @(not P ; not Q)@, which is the same as saying
@not (P ; Q)@ is equivalent to @(not P, not Q)@.  We prove this in two
stages, first starting with the assumption @not (P, Q)@.
\begin{verbatim}
 1      not (P, Q)              given

 2.L    not P                   assuming the left hand side of 1 is false
 3.L    (not P ; not Q)         from the disjunction rules and 2.L

 2.R    not P                   assuming the right hand side of 1 is false
 3.R    (not P ; not Q)         from the disjunction rules and 2.R

 4      (not P ; not Q)         from 1, 3.L and 3.R
\end{verbatim}
Going the other way, we assume @not (P ; Q)@.
\begin{verbatim}
 1      not (P ; Q)             given

 2      not P                   from the disjunction rules and 1
 3      not Q                   from the disjunction rules and 1
 4      (not P, not Q)          from the conjunction of 2 and 3
\end{verbatim}

The \emph{resolution} rule for disjunctions says that if one disjunct is
false then the other must be true:
\begin{verbatim}
 1      (P ; Q)                 given
 2      not P                   given

 3      (not P => Q)            equivalent to 1
 4      Q                       modus ponens over 2 and 3
\end{verbatim}
As a special case of this rule we see that @P@ must follow from
@(false ; P)@.

Aristotle's \emph{law of the excluded middle} states that the
disjunction of a proposition with itself must be true:
\begin{verbatim}
 1      (P ; not P)             given

 2      true                    trivial
 3      (P => true)             from the implication rules and 2
 4      (not P => true)         from the implication rules and 2

 5.L    P                       assuming the left hand side of 1
 6.L    true                    modus ponens over 5.L and 3

 5.R    not P                   assuming the right hand side of 1
 6.R    true                    modus ponens over 5.R and 4

 7      true                    from 1, 6.L and 6.R
\end{verbatim}

Implication is transitive:
\begin{verbatim}
 1      (P => Q)                given
 2      (Q => R)                given

 3.L    not P                   assuming antecedent of 1 is false
 4.L    (P => R)                from implication rules and 3.L

 3.R    Q                       assuming consequent of 1 is true
 4.R    R                       modus ponens over 3.R and 2
 5.R    (P => R)                from implication rules and 4.R

 6      (P => R)                from 1, 2, 4.L and 5.R
\end{verbatim}

\subsection{Cavilling Vilely}

\XXX{Check this isn't copyright!  It's been doing the Cambridge Tripos
rounds for years, at least.}

Consider the following somewhat contorted problem statement:
\begin{quote}
If Anna can cancan or Kant can't cant, then Greville will cavil vilely.
If Greville will cavil vilely, Will will want.
But Will \emph{won't} want.
So can Kant cant?
\end{quote}
How can we use propositional logic to decide the truth of the question?
Here's how.  We start by labelling the various propositions:
\begin{description}
\item let @a@ stand for ``Anna can cancan'';
\item let @k@ stand for ``Kant can cant'';
\item let @g@ stand for ``Greville will cavil vilely'';
\item and let @w@ stand for ``Will will want''.
\end{description}

Our axioms are obtained by translating the statement of the problem into
sentences in propositional logic:
\begin{verbatim}
 1      ((a ; not k) => g)      given
 2      (g => w)                given
 3      not w                   given
\end{verbatim}
Our \emph{goal} is to find a proof of either @k@ or @not k@; we can
obtain a proof of the former as follows (and since the problem statement
and logic are consistent, this means we can't prove the latter):
\begin{verbatim}
 4      not g                   from the implication rules and 3 and 2
 5      not (a ; not k)         from the implication rules and 4 and 1
 6      (not a, k)              De Morgan's law applied to 5
 7      k                       projecting the right hand side of 6
\end{verbatim}
So Kant \emph{can} cant after all!

\subsection{On Obtaining Proofs}

Finding a proof or disproof of a formula is not straightforward.  Since
this book only introduces logic, an in-depth treatment of proof
procedures is beyond its scope.  However, it behooves us to say a few
words on the subject.

The key idea in obtaining a proof is to work backwards from the goal.
One has to look at the inference rules and the axioms of the problem
domain and search for steps that will break down the goal into simpler
subgoals.  This procedure continues until the subgoals are either
trivial (deducible without axioms) or are themselves in the set of
axioms.  The tricky part is that one may need to handle disjunctions (it
is sometimes simpler to convert implications into their equivalent
disjunctive forms) by proving that the goal is provable regardless of
which disjunct is true.  Finding proofs is not easy and takes some
practice before one becomes proficient.

Note that if you don't \emph{know} that a particular formula is true or
false then one has to simultaneously look for proofs of both
possibilities: in a consistent theory you cannot find a disproof of a
theorem or a proof of a non-theorem!

While complete proof algorithms exist for deciding the truth of
arbitrary formulae in the propositional calculus (see the
\XXX{Davis-Putnam method}, for instance), unfortunately its more
expressive cousin, the predicate calculus, does not admit this property
(that is, there is no way to construct an algorithm to decide whether an
arbitrary predicate calculus formula is true or false.)  Mercury can be
viewed as implementing a correct, but incomplete, proof procedure for
first order logic.  But don't worry about that for now.

\subsection{Informal Shortcuts}

We often want to sketch out a proof quickly before writing it down in a
formal fashion (if, indeed, we decide we need this level of rigour.)  In
such situations it is acceptable to take a ``term rewriting'' approach:
given @P <=> Q@ we can always substitute @P@ for @Q@ and vice versa;
given @P => Q@ we may substitute @P@ for @Q@ in the antecedent of
implications and @Q@ for @P@ in the consequent of implications.  Below
is a handy selection of ``rewriting'' rules:
\begin{verbatim}
(P => Q)             <=>  (not Q => not P)
(P => Q)             <=>  (not P ; Q)
((P, Q) => R)        <=>  (P => (Q => R))

not true             <=>  false
not false            <=>  true
not not P            <=>  P

(P, not P)           <=>  false
(P, false)           <=>  false
(P, true)            <=>  P

(P ; not P)          <=>  true
(P ; true)           <=>  true
(P ; false)          <=>  P

((P => Q), (Q => R))  =>  (P => R)
(P, Q)                =>  P
(not P, (P, Q))       =>  Q
\end{verbatim}

\subsection{An Interesting Observation}

The reader may find it interesting to note that one can construct all
the rules of inference of propositional logic using just implication and
falsity:
\begin{verbatim}
not P                <=>  (P => false)
(P ; Q)              <=>  (not P => Q)
(P, Q)               <=>  ((P => not Q) => false)
\end{verbatim}

\section{Predicate Logic}

The expressive power of propositional logic is rather limited.  The key
problem is that it makes no provision for making general statements such
as, ``The square of an odd number is also an odd number.''  Instead one
is forced into writing down an (in this case) infinite number of
propositions of the form ``$1$ is an odd number'', ``$1^2$ is an odd
number'', ``$3$ is an odd number'', ``$3^2$ is an odd number'' and so
forth.  The relationship between odd numbers and this property of their
squares is not explicitly represented, other than as a correspondence
amongst the set of axioms.

Mercury programs are restricted predicate calculus theories; it is
actually very helpful to bear this in mind when reasoning about them.

\subsection{Language}

The language of predicate calculus is slightly more complicated than
that for propositional logic, introducing as it does logical variables,
terms and parameterised predicates.
\begin{itemize}
\item \emph{Terms} represent objects in the problem domain, such as
numbers, people, and so forth.  Terms can be structured -- a list of
terms would itself be a perfectly good term.
\item \emph{Logical variables} range over terms and appear as parameters
to predicates.
\item \emph{Predicates} represent properties of terms.  Unlike
propositions, predicates may be parameterized.  For example, we might
have a predicate @odd(X)@ to denote @X@ being an odd number, or a
predicate @parent(A, B)@ to denote @A@ being a parent of @B@.  We
normally assume the usual equality relation, @=@.
\end{itemize}
Sticking with Mercury syntax, predicates and term names start with
@lower case@ letters (unless we are using symbols for conveience, such
as @123@ or @*@ or list notation and such like.)  Variable names start
with @Upper Case@ letters.

Formulae are composed in much the same way as for the propositional
calculus, with the addition of two ways of introducing logical
variables.  Taking @P@ and @Q@ to stand for arbitrary logical formulae:
\begin{itemize}
\item @not P@ stands for the \emph{negation} ``@P@ is false'';
\item @(P, Q)@ stands for the \emph{conjunction} ``@P@ and @Q@'' meaning
\emph{both} @P@ and @Q@ are true;
\item @(P ; Q)@ stands for the \emph{disjunction} ``@P@ or @Q@'' meaning
\emph{at least one of} @P@ and @Q@ is true;
\item @(P => Q)@ stands for the \emph{implication} ``if @P@ then @Q@'';
\item @(some [X] P)@ stands for the \emph{existential
quantification} ``for some value of @X@ @P@'';
\item @(all [X] P)@ stands for the \emph{universal
quantification} ``for all values of @X@ @P@'';
\end{itemize}

We allow several variables to appear in the list of a quantification
with the understanding that
\begin{verbatim}
(some [X, Y, Z] P)
\end{verbatim}
really means
\begin{verbatim}
(some [X] (some [Y] (some [Z] P)))
\end{verbatim}

We will allow ourselves to use a pattern matching shorthand in
definitions (@<=>@) and implications (@=>@ and @<=@), so rather than
writing
\begin{verbatim}
(all [X] (p(X) <= X = 42))
\end{verbatim}
we simply write
\begin{verbatim}
p(42)
\end{verbatim}
to mean the same thing.

Returning briefly to our ``square numbers'' example, we would write that
as
\begin{verbatim}
(all [X, Y] ((odd(X), square(X, Y)) => odd(Y)))
\end{verbatim}
which reads as ``for all values of @X@ and @Y@, if @X@ is odd and @Y@ is
the square of @X@, then @Y@ is odd.''

\subsection{Rules of Inference}

For the most part, the rules of inference for the predicate calculus
appear identical to those for the propositional calculus.  The important
difference is the rules that dictate how variables are handled.

We can always infer @true@, which is the negation of @false@.
The double negation of a proposition is the same as asserting that
proposition.
\begin{verbatim}
                                not not P       P
-----           ----------      ----------      ----------
true            not false       P               not not P
\end{verbatim}
(If we omit the double negation rule then we have an intuitionistic
logic.)

We can form the conjunction of any two true propositions.
We can reorder conjunctions.
We can project a conjunct from a conjunction.
Conjunction with any false proposition is also false.
\begin{verbatim}
P
Q               P, Q            P, Q            not P
-----           -----           -----           ----------
P, Q            Q, P            P               not (P, Q)
\end{verbatim}

We can form a disjunction of any other proposition with a true
proposition.
We can reorder disjunctions.
If a disjunction is false then so are its disjuncts.
\begin{verbatim}
                                                not P
P               P ; Q           not (P ; Q)     not Q
------          ------          ------------    ------------
P ; Q           Q ; P           not P           not (P ; Q)
\end{verbatim}

If the antecedent of an implication is true then the consequent must
also be true (\emph{modus ponens}).
If the consequent of an implication is false then the antecedent must
also be false (\emph{modus tollens}).
We can introduce an implication using any proposition at all for a true
consequent or a false antecedent:
\begin{verbatim}
P               not Q
P => Q          P => Q          Q               not P
-------         -------         -------         -------
Q               not P           P => Q          P => Q
\end{verbatim}

We can substitute any term at all for a universally quantified
variable.
The dual of universal quantification is existential quantification.
\begin{verbatim}
all [X] P       some [X] P
----------      --------------------
P[a/X]          not (all [X] not P)

P[a/X]          not (all [X] not P)
-----------     --------------------
some [X] P      some [X] P
\end{verbatim}
where @P[a/X]@ means @P@ with the term @a@ replacing all free
occurrences of @X@ therein.  A free variable is one not in the scope of
any enclosing quantification.  For instance, @X@ is free in @odd(X)@,
but not in @some [X] odd(X)@.

\XXX{Check the above sequents.  I think there's a bug.}

\subsection{Finding the Length of a List}

Here's an example of how we can use logic to work out the length of a
list.
\begin{verbatim}
all [X, Y]
    length(Xs, N) <=>
        (
            (Xs = [], N = 0)
        ;
            some [X0, Xs0, N0]
                (   Xs = [X0 | Xs0],
                    length(Xs0, N0),
                    N  = N0 + 1
                )
        )
\end{verbatim}
which, incidentally, corresponds to the Mercury definition
\begin{verbatim}
length([],         0     ).
length([X0 | Xs0], N0 + 1) :- length(Xs0, N0).
\end{verbatim}

First, let's see how we can prove @length([a, b], 2)@ (remember, we
construct this proof bottom-up):
\begin{verbatim}
 1      [] = []
 2      0  = 0
 3      ([] = [], 0 = 0)
 4      (([] = [], 0 = 0) ; ...)
 5      length([], 0)

 6      [b]    = [b | []]
 7      0 + 1  = 0 + 1
 8      ([b] = [b | []], length([], 0), 0 + 1 = 0 + 1)
 9      some [X0, Xs0, N0] ([b] = [X0 | Xs0], ...)
   ...
10      length([b], 0 + 1)

11      [a, b]    = [a | [b]]
12      0 + 1 + 1 = 0 + 1 + 1
13      ([a, b] = [a | [b]], length([b], 0 + 1), 0 + 1 + 1 = 0 + 1 + 1)
14      some [X0, Xs0, N0] ([a, b] = [a | [b]], ...)
   ...
15      length([a, b], 0 + 1 + 1)
\end{verbatim}
and provided we accept that @0 + 1 + 1 = 2@ then our work here is done.

We haven't actually \emph{calculated} anything here; rather we've just
proved something we strongly suspected was true anyway.  What we really
want to do, as logic programmers, is find some way of working out, for
instance, what @N@ satisfies @length([a, b, c], N)@.

Just as we can take a term rewriting approach to solving problems in
propositional logic, we can use similar shortcuts in predicate logic.
In particular, this will avoid the need for us to pluck the right terms
from thin air when looking for a proof of a formula containing variables.
We use the following ``tricks'' while working backwards from the
top-level goal:
\begin{itemize}
\item existentially quantified variables are left in the 
\end{itemize}
\XXX NEED TO SORT THIS BIT OUT.





De Morgan's laws extend to cover quantification, giving us the following
identities:
\begin{align*}
\All{X}{p}
& \Eqv \Not{\Some{X}{\Not{p}}} \\
\Some{X}{p}
& \Eqv \Not{\All{X}{\Not{p}}} \\
\end{align*}

Since the names of quantified variables do not matter, we can rename
them at will.

\subsection{Using Quantifiers}

From $\All{X}{p}$ we can deduce $p[t/X]$ for any term $t$.  The
expression $p[t/X]$ denotes the application of the \emph{substitution}
$[t/X]$ to $p$ -- that is, all free occurrences of $X$ in $p$ are
replaced with $t$.  Substitution works as follows:
\begin{align*}
\text{(Over terms)} \\
X[t/X]
& = t \\
Y[t/X]
& = Y \text{ provided $X$ and $Y$ are different variables} \\
f(t_1, t_2, \ldots, t_n)[t/X]
& = f(t_1[t/X], t_2[t/X], \ldots, t_n[t/X]) \\
\text{(Over formulae)} \\
a(t_1, t_2, \ldots, t_n)[t/X]
& = a(t_1[t/X], t_2[t/X], \ldots, t_n[t/X]) \\
\Not{p}[t/X]
& = \Not{(p[t/X])} \\
(p \Conj q)[t/X]
& = (p[t/X] \Conj q[t/X]) \\
(p \Disj q)[t/X]
& = (p[t/X] \Disj q[t/X]) \\
(p \Imp q)[t/X]
& = (p[t/X] \Imp q[t/X]) \\
(\All{X}{p})[t/X]
& = \All{X}{p} \\
(\All{Y}{p})[t/X]
& = \All{Y}{p[t/X]} \text{ provided $X$ and $Y$ are different variables} \\
(\Some{X}{p})[t/X]
& = \Some{X}{p} \\
(\Some{Y}{p})[t/X]
& = \Some{Y}{p[t/X]} \text{ provided $X$ and $Y$ are different variables} \\
\end{align*}

From $p(t)$, for any term $t$, we can deduce $\Some{X}{p(X)}$.  Or, more
correctly, given $p[t/X]$ we conclude $\Some{X}{p}$.

We can simplify quantified formulae:
\begin{align*}
\All{X}{p \Conj q}
& \Eqv \All{X}{p} \Conj \All{X}{q}\\
\Some{X}{p \Conj q}
& \Eqv \Some{X}{p} \Conj \Some{X}{q}
\end{align*}

Provided $X \notin \FV(p)$ can rearrange quantifiers like so:
\begin{align*}
p \Conj \All{X}{q}
& \Eqv \All{X}{p \Conj q} \\
p \Conj \Some{X}{q}
& \Eqv \Some{X}{p \Conj q} \\
\end{align*}
The constraint is required because we do not want to inadvertently
\emph{capture} a free variable that happens to be called $X$ in $p$ in
the quantifier.  We can always move quantifiers out to the outermost
level by renaming variables as necessary.

\subsection{An Example: Schubert's Steamroller}

This rather knotty problem was devised by Mark E. Schubert \XXX{}.

We start off with a statement of the problem in plain English.
\begin{itemize}
\item Snails, caterpillars, birds, foxes and wolves are all animals.
\item Grain is a kind of plant.
\item Each species of animal eats all types of plants
or all species of smaller animals that eat some types of plants.
\item Wolves are bigger than foxes, foxes are bigger than birds, and
birds are bigger than caterpillars and snails.
\item Wolves don't eat foxes or grain.  Birds eat caterpillars, but not snails.
Caterpillars and snails like to eat plants.
\item \textbf{Is there an animal that eats a grain-eating animal?}
\end{itemize}

Now let's translate the axioms of the problem into logical formulae:
\begin{tabular}{rl}
    &  (Axioms.) \\
(1a) & $\Animal(\Snail)$ \\
(1b) & $\Animal(\Caterpillar)$ \\
(1c) & $\Animal(\Bird)$ \\
(1d) & $\Animal(\Fox)$ \\
(1e) & $\Animal(\Wolf)$ \\
\\
(2) & $\Plant(\Grain)$ \\
\\
(3) & $\All{X}{\Animal(X) \Imp \Herbivorous(X) \Disj \Carnivorous(X)}$ \\
(3a) & $\All{X}{\Herbivorous(X) \Eqv$ \\
     & $\qquad \All{Y}{\Eats(X, Y) \Bimp \Plant(Y)}}$ \\
(3b) & $\All{X}{\Carnivorous(X) \Eqv$ \\
     & $\qquad \All{Y}{\Eats(X, Y) \Bimp
                    \BiggerThan(X, Y) \Conj
                    \Some{Z}{\Plant(Z) \Conj \Eats(Y, Z)}}}$ \\
                    \\
(4a) & $\BiggerThan(\Wolf, \Fox)$ \\
(4b) & $\BiggerThan(\Fox, \Bird)$ \\
(4c) & $\BiggerThan(\Bird, \Caterpillar)$ \\
(4d) & $\BiggerThan(\Bird, \Snail)$ \\
\\
(5a) & $\Not{\Eats(\Wolf, \Fox)}$ \\
(5b) & $\Not{\Eats(\Wolf, \Grain)}$ \\
(5c) & $\Eats(\Bird, \Caterpillar)$ \\
(5d) & $\Not{\Eats(\Bird, \Snail)}$ \\
(5e) & $\Herbivorous(\Caterpillar)$ \\
(5f) & $\Herbivorous(\Snail)$ \\
\end{tabular}

The goal is then $\Some{X, Y}{\Eats(X, Y) \Conj \Eats(Y, \Grain)}$.

It turns out that the answer to the conundrum is that foxes eat birds
who eat grain (it's probably easier to write a computer program called a
\emph{theorem prover} to work this out than to do so by trying out each
combination by hand\ldots)  But how can we prove this?  Here's how:

\begin{tabular}{rl}
& (Deduce that wolves are carnivorous.) \\
(6) & $\Not{\Eats(\Wolf, \Grain)} \Conj \Plant(\Grain)$
\\ & --- by (5b) and (2) \\
(7) & $\Some{Y}{\Not{\Eats(\Wolf, Y)} \Conj \Plant(Y)}$
\\ & --- from (6) \\
(8) & $\Not{\All{Y}{\Eats(\Wolf, Y) \Disj \Not{\Plant(Y)}}}$
\\ & --- from (7) \\
(9) & $\Not{\All{Y}{\Eats(\Wolf, Y) \Bimp \Plant(Y)}}$
\\ & --- from (8) \\
(10) & $\Not{\Herbivorous(\Wolf)}$
\\ & --- from (9) and definition of $\Herbivorous$ (3a) \\
(11) & $\Carnivorous(\Wolf)$
\\ & --- by (10) and (3) via resolution \\
\\
& (Deduce therefore that foxes are carnivorous.) \\
(12) & $\All{Y}{\Eats(\Wolf, Y) \Bimp
            \BiggerThan(\Wolf, Y) \Conj
            \Some{Z}{\Plant(Z) \Conj \Eats(Y, Z)}}$
\\ & --- by (11) and (3b) via modus ponens \\
(13) & $\All{Y}{\Not{\Eats(\Wolf, Y)} \Imp
            \Not{\BiggerThan(\Wolf, Y)} \Disj
            \Not{\Some{Z}{\Plant(Z) \Conj \Eats(Y, Z)}}}$
\\ & --- contrapositive of (12) \\
(14) & $\Not{\BiggerThan(\Wolf, \Fox)} \Disj
            \Not{\Some{Z}{\Plant(Z) \Conj \Eats(\Fox, Z)}}$
\\ & --- by (13) and (5a) via modus ponens \\
(15) & $\Not{\Some{Z}{\Plant(Z) \Conj \Eats(\Fox, Z)}}$
\\ & --- by (14) and (4a) via resolution \\
(16) & $\All{Z}{\Not{\Eats(\Fox, Z)} \Bimp \Plant(Z)}$
\\ & --- from (15) \\
(17) & $\Not{\Eats(\Fox, \Grain)}$
\\ & --- by (16) and (2) via modus ponens \\
(18) & $\Not{\Eats(\Fox, \Grain)} \Conj \Plant(\Grain)$
\\ & --- by (17) and (2) \\
(19) & $\Some{Y}{\Not{\Eats(\Fox, Y)} \Conj \Plant(Y)}$
\\ & --- by (18) \\
(20) & $\Not{\All{Y}{\Eats(\Fox, Y) \Bimp \Plant(Y)}}$
\\ & --- by (19) \\
(21) & $\Not{\Herbivorous(\Fox)}$
\\ & --- by definition of $\Herbivorous$ (3a) \\
(22) & $\Carnivorous(\Fox)$
\\ & --- by (21) and (3) via resolution \\
\end{tabular}
So we've identified that the foxes eat all animals that eat some kind of
plant.  All we have to do now is show that birds eat grain, and hence
that foxes eat birds, and we have proved the goal.

\begin{tabular}{rl}
(23) & $\All{Y}{\Eats(\Snail, Y) \Bimp \Plant(Y)}$
\\ & --- by definition of $\Herbivorous(\Snail)$ (3a) \\
(24) & $\Eats(\Snail, \Grain)$
\\ & --- by (23) and (2) via modus ponens \\
(25) & $\Plant(\Grain) \Conj \Eats(\Snail, \Grain)$
\\ & --- by (24) and (2) \\
(26) & $\Some{Z}{\Plant(Z) \Conj \Eats(\Snail, Z)}$
\\ & --- by (25) \\
(27) & $\Not{\Eats(\Bird, \Snail)} \Conj
        \BiggerThan(\Bird, \Snail) \Conj
        \Some{Z}{\Plant(Z) \Conj \Eats(\Snail, Z)}$
\\ & --- by (26), (5d) and (4d) \\
(28) & $\Some{Y}{
            \Not{\Eats(\Bird, Y)} \Conj
            \BiggerThan(\Bird, Y) \Conj
            \Some{Z}{\Plant(Z) \Conj \Eats(Y, Z)}}$
\\ & --- by (27) \\
(29) & $\Not{\All{Y}{
            \Eats(\Bird, Y) \Bimp
            \BiggerThan(\Bird, Y) \Conj
            \Some{Z}{\Plant(Z) \Conj \Eats(Y, Z)}}}$
\\ & --- by (28) \\
(30) & $\Not{\Carnivorous(\Bird)}$
\\ & --- by definition of $\Not{\Carnivorous(\Bird)}$ (3b) \\
(31) & $\Herbivorous(\Bird)$
\\ & --- by (30) and (3) via resolution \\
(32) & $\All{Y}{\Eats(\Bird, Y) \Bimp \Plant(Y)}$
\\ & --- by definition of $\Herbivorous(\Bird)$ (3a) \\
(33) & $\Eats(\Bird, \Grain)$
\\ & --- by (33) and (2) via modus ponens \\
(34) & $\Plant(\Grain) \Conj \Eats(\Bird, \Grain)$
\\ & --- by (33) and (2) \\
(35) & $\Some{Z}{\Plant(Z) \Conj \Eats(\Bird, Z)}$
\\ & --- by (34) \\
(36) & $\BiggerThan(\Fox, \Bird) \Conj
        \Some{Z}{\Plant(Z) \Conj \Eats(\Bird, Z)}$
\\ & --- by (35) and (4b) \\
(37) & $\All{Y}{\Eats(\Fox, Y) \Bimp
            \BiggerThan(\Fox, Y) \Conj
            \Some{Z}{\Plant(Z) \Conj \Eats(Y, Z)}}$
\\ & --- by (22) and definition of $\Carnivorous(\Fox)$ (3b) \\
(38) & $\Eats(\Fox, \Bird)$
\\ & --- by (37) and (36) via modus ponens \\
(39) & $\Eats(\Fox, \Bird) \Conj \Eats(\Bird, \Grain)$
\\ & --- by (38) and (33) \\
(40) & $\Some{X, Y}{\Eats(X, Y) \Conj \Eats(Y, \Grain)}$
\\ & --- by (39) \\
QED \\
\end{tabular}

Well, that was hard work (in practice, when writing a paper, we would
omit many of the smaller steps in the above.)  Still, we should now have
some sort of feel for first order logic.

The point of this exercise is XXX HERE

\subsection{Aside on higher order programming?}

\XXX{We can treat closures not as higher order terms, but rather as
structures containing (amongst other things) \emph{names} of predicates
which can be interpreted by some special machinery that handles higher
order application.}

\section{Using Predicate Logic for Computation}

Horn clauses.

Proof procedures.

Clark completion.

Negation and the CWA.

Modes.



